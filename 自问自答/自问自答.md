# 自问自答

我想做什么？

发布属于自己的docker镜像，该镜像有kafka集群环境

我想先拉个7.0的centos镜像

```cmd
docker pull centos:centos7
```

我想自己制作一个含zookeeper镜像

```dockerfile
FROM centos:centos7
MAINTAINER 13265317096@163.com


# 把java添加到容器中  ADD命令会自动处理URL和解压tar压缩包
ADD jdk1.8.0_333.tar.gz /usr/local/
ADD zookeeper_3510.tar.gz /usr/local/
ADD zookeeper_start.sh  /usr/local/

RUN yum -y install vim

RUN chmod 755 /usr/local/zookeeper_start.sh


#配置java与环境变量
ENV  JAVA_HOME /usr/local/jdk1.8.0_333
ENV  JRE_HOME  $JAVA_HOME/jre 
ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
ENV PATH $PATH:$JAVA_HOME/bin:$JRE_HOME/bin

ENTRYPOINT /usr/local/zookeeper_start.sh

```

在arm64上构建镜像，需要指定platform

```bash
docker build --platform linux/amd64 -t dexlace/zookeeper .
```



```bash
docker run --rm :
--rm: 容器退出时会清除挂载的卷，以便清除数据

docker run --rm --name myzookeeper -p 2181:2181 -v /Users/dexlace/docker/zookeeper_instance/data:/usr/local/zookeeper_3510/data -d dexlace/zookeeper:latest


docker run --name zookeeper -p 2181:2181 -v /Users/dexlace/docker/zookeeper_instance/data:/usr/local/zookeeper_3510/data  dexlace/zookeeper:latest


```

进入docker容器中

```bash
docker exec -it 4033aa7ab7e9 /bin/bash
```

```bash
运行
zkCli.sh -server 127.0.0.1:2181
```

## 先温习一下zookeeper

### 命令行基本操作

- 查看znode所包含的节点

```bash
ls /  # 查看当前节点
ls2 /  # 查看当前节点详细数据
ls /zhongguo  # 查看节点zhongguo

```

- 创建节点

```bash
create /zhongguo  # 创建普通节点
create /zhongguo "qinshihuang"  # 创建节点并同时设置节点的值
create -e /meiguo "linken"  # 创建临时节点并设置节点的值
create -s /yindu "asan" # 创建带序号的节点
```

- 设置节点的值

```bash
set /eluosi "pujing"  # 设置节点的值
```

- 监听节点值的变化

```bash
get /zhongguo watch # 监听节点/zhongguo的变化
```

- 监听路径变化

```bash
ls /zhongguo watch  # 监听节点/zhongguo的路径变化
```

- 删除节点

```bash
delete /zhongguo # 删除/zhongguo节点
```

- 递归删除节点

```bash
rmr /sangguo/shuguo
```

- 查看节点的状态

```bash
stat /sanguo
```

### zookeeper的acl控制

- 即用==授权策略==对==授权对象==施加==何种权限==

- - ==方式一==：world 只有一个用户：anyone，**代表登录zokeeper所有人（默认）**

  - ```bash
    setAcl <path> world:anyone:<acl> # world:anyone:<acl>表示授权策略:授权对象:授权权限
    ```

  - ```bash
    # 比如给zhangsan节点添加world授权策略，作用在anyone上，权限是crdwa
    # crdwa 是创建、读、写、删除的缩写，再加一个a 表示可以设置节点访问控制列表权限
    setAcl /zhangsan world:anyone:crdwa
    ```

  - ==方式二：ip，对客户端使用ip地址认证==

  - ```bash
    setAcl <path> ip:<ip>:<acl>
    ```

  - ```bash
    setAcl /node2 ip:192.168.60.129:cdrwa
    ```

  - ==方式三：auth授权模式==

  - ```bash
    addauth digest <user>:<password> #添加认证用户 
    setAcl <path> auth:<user>:<acl>
    ```

  - ==方式四：digest授权模式==

  - ```bash
    setAcl <path> digest:<user>:<password>:<acl>
    # 密码是经过SHA1及BASE64处理的密文
    ```

  - 以上多种模式可以混用

    



### JAVA API操作

- 连接

```java
// 1、 先实现一个zookeeper连接需要传入的watcher对象
@Slf4j
public class MyZkWatcher implements Watcher {

    //异步锁
    private CountDownLatch cdl;

    //标记
    private String mark;

    public MyZkWatcher(CountDownLatch cdl,String mark) {
        this.cdl = cdl;
        this.mark = mark;
    }

    //监听事件处理方法
    @Override
    public void process(WatchedEvent event) {
        log.info(mark+" watcher监听事件：{}",event);
        cdl.countDown();
    }


}

```

```java
@Slf4j
public class MyZkConnect {

    //集群节点
    public static final String zkServerClusterConnect = "192.168.205.100:2181,192.168.205.101:2181,192.168.205.102:2181";

    //单一节点
    public static final String zkServerSingleConnect = "127.0.0.1:2181";

    //超时毫秒数
    public static final int timeout = 3000;
  
   public static ZooKeeper connect() throws IOException, InterruptedException{
       // 记得go 的wait group的类似用法就能释然了
        CountDownLatch cdl = new CountDownLatch(1);
        log.info("准备建立zk服务");
        ZooKeeper zk = new ZooKeeper(zkServerSingleConnect, timeout, new MyZkWatcher(cdl,"建立连接"));
        log.info("完成建立zk服务");
        cdl.await();//这里为了等待wather监听事件结束
        return zk;
    }

    public static void main(String[] args) throws InterruptedException, IOException, KeeperException {
        //建立连接
        ZooKeeper zk = connect();
        //zk.close();//关闭后不支持重连
        log.info("zk 状态："+zk.getState());

    }
```

- 新增节点

```java
// 同步方式 
// 第一个是节点路径 
// 第二个参数是节点存储的数据
// 第三个是acl访问控制列表  ZooDefs.Ids 静态接口来获取一些基本的acl列表
// 第四个是节点的枚举类型
create(String path, byte[] data, List<ACL> acl, CreateMode createMode) ;
 
  
// 异步方式 
create(String path, byte[] data, List<ACL> acl, CreateMode createMode， AsyncCallback.StringCallback callBack,Object ctx);
```

- 查询节点
- - 状态

```java
Stat exists(String path,boolean watch);
// 异步方法 
exists(String path, boolean b，AsyncCallback.StatCallback callBack,Object ctx)
```

- - 数据

```java
// 同步方式 
getData(String path, boolean b, Stat stat) 
// 异步方式 
getData(String path, boolean b，AsyncCallback.DataCallback callBack， Object ctx)
```

- 更新节点

```java
// 同步方式  version从stat获取
  setData(String path, byte[] data, int version) 
  // 异步方式 
  setData(String path, byte[] data, int version，AsyncCallback.StatCallback callBack， Object ctx)
```

- 删除节点

```java
// 同步方式 version为-1时表示删除时不考虑版本信息
delete(String path, int version) 
// 异步方式 
delete(String path, int version, AsyncCallback.VoidCallback callBack, Object ctx)
```

- 查看子节点

```java
// 同步方式  b 是否使用连接对象中注册的监视器
getChildren(String path, boolean b) 
// 异步方式 
getChildren(String path, boolean b,AsyncCallback.ChildrenCallback callBack,Object ctx)
```

### watcher接口

zookeeper提供了==数据的发布/订阅功能==，多个订阅者==可同时监听某一特定主题对象==，当该主题对象的自身状态发生变化时(例如节点内容改变、节点下的子节点列表改变等)，==会实时、主动通知所有订阅者==

两个**内部枚举类**

- Watcher通知状态（KeepState）：客户端与服务端连接状态发生变化时对应的通知类型

```bash
SyncConnected    # 客户端与服务器正常连接时
Disconnected     # 客户端与服务器断开连接时
Expired          # 会话session失效时
AuthFailed       # 身份认证失败时
```

- Watcher事件类型（EventType）:数据节点发生变化时对应的通知类型。EventType变化时 ，KeeperState永远处于SyncConnected通知状态下；当KeeperState发生变化时， EventType永远为None。

```bash
None; NodeCreated; NodeDeleted; NodeDataChanged; NodeChildrenChanged
```

注：客户端接收到的相关事件通知中==**只包含状态及类型等信息**==，不包括节点变化前后的具体内容，变化前的数据需业务自身存储，变化后的数据需调用get等方法重新获取

#### 配置中心例子

- ==**连接**==

```java
// 封装连接
public class ZkConnection {

    private static ZooKeeper zk;

    private static String connectString = "127.0.0.1:2181/testConf";

    private static CountDownLatch cdl = new CountDownLatch(1);

    public static ZooKeeper getZK() {

        try {
            zk = new ZooKeeper(connectString, 3000, new ConnectionWatcher(cdl));
            cdl.await(); // 同步阻塞，维护zk的连接创建成功
        } catch (Exception e) {
            e.printStackTrace();
        }

        // 1. 为了保证返回的zk一定建立连接，使用CountDownLatch
        return zk;
    }
}

```

连接的watcher

```java

// 处理连接的watcher
public class ConnectionWatcher implements Watcher {

    private CountDownLatch cdl;

    public ConnectionWatcher(CountDownLatch cdl) {
        this.cdl = cdl;
    }

    @Override
    public void process(WatchedEvent watchedEvent) {
        System.out.println(watchedEvent.toString());
        Event.KeeperState state = watchedEvent.getState();
        switch (state) {
            case Unknown:
                break;
            case Disconnected:
                break;
            case NoSyncConnected:
                break;
            case SyncConnected:
                // 这一行来保证连接的
                // 保持连接
                cdl.countDown();
                break;
            case AuthFailed:
                break;
            case ConnectedReadOnly:
                break;
            case SaslAuthenticated:
                break;
            case Expired:
                break;
            case Closed:
                break;
        }
    }
}

```

- 监听节点的watcher

```java


// 处理节点监听
public class NodeWatcher implements Watcher, AsyncCallback.StatCallback, AsyncCallback.DataCallback {

    private ZooKeeper zk;

    private MyConf myConf;

    private CountDownLatch cdl = new CountDownLatch(1);

    public NodeWatcher(ZooKeeper zk) {
        this.zk = zk;
    }

    public void setMyConf(MyConf myConf) {
        this.myConf = myConf;
    }

    // 给节点绑定一个事件
    @Override
    public void process(WatchedEvent watchedEvent) {
        switch (watchedEvent.getType()) {

            case None:
                break;
            case NodeCreated:
                zk.getData("/testConf", this, this, "version-1");
                System.err.println("/testConf节点创建......");
                cdl.countDown();
                break;
            case NodeDeleted:
                myConf.setConf("");
                cdl = new CountDownLatch(1);
                System.err.println("/testConf节点被删除......");
                break;
            case NodeDataChanged:
                zk.getData("/testConf", this, this, "version-1");
                System.err.println("/testConf节点被修改......");
                break;
            case NodeChildrenChanged:
                break;
            case DataWatchRemoved:
                break;
            case ChildWatchRemoved:
                break;

        }

    }

    // exists 的回调
    @Override
    public void processResult(int i, String s, Object o, Stat stat) {
        // 如果stat不为空，说明有节点，可以直接取数据
        if (stat != null) {
            // 这里第二个参数还要传watcher，为了持续绑定事件
            zk.getData("/testConf", this, this, "version-1");
            // 存在且计数器没有变为0  则需要减去1 被创建时也需要减去1
            if(cdl.getCount()==1){
                cdl.countDown();
            }
        }


    }

    // getData的回调
    @Override
    public void processResult(int i, String s, Object o, byte[] bytes, Stat stat) {
        if(bytes==null){
            myConf.setConf("Node of no value");
        }else{
            myConf.setConf(new String(bytes));
        }

    }


    // 主要调用exists方法
    public void aWait() {
        try {
            System.err.println("await start ...");
            zk.exists("/testConf", this, this, "version-0");
            // 如果不存在会一直阻塞
            cdl.await();
            System.err.println("await finish ...");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}



```

配置文件读取类：

```java
@Data
@NoArgsConstructor
@AllArgsConstructor
@ToString
public class MyConf {
    private String conf;
}
```

测试：

```java
public class ConfigCenterTest {

    ZooKeeper zk;

    @Before
    public void connect() {
        zk = ZkConnection.getZK();
        System.out.println("connection finish...");
    }

    @After
    public void close() {
        try {
            zk.close();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    @Test
    public void testContent() {
        NodeWatcher nodeWatcher = new NodeWatcher(zk);
        MyConf myConf = new MyConf();
        // 设置读取的变量
        nodeWatcher.setMyConf(myConf);

        //1. 开始创建的时候没有节点，应该进行阻塞
        nodeWatcher.aWait();
        System.err.println("节点已创建...");

        // 下面的while循环是核心
        while (true) {
            nodeWatcher.aWait();
            System.err.println(myConf);
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

}
```

#### 生成分布式唯一ID

```java
package com.scct.zookeeper.test.cases;

import com.scct.zookeeper.test.watcher.ZKConnectionWatcher;
import org.apache.zookeeper.*;

import java.util.concurrent.CountDownLatch;

/**
 * @Author: xiaogongbing
 * @Description:
 * @Date: 2021/3/2
 */
public class GloballyUniqueId implements Watcher {
    // zk的连接串
    String IP = "127.0.0.1:2181";
    // 计数器对象
    CountDownLatch countDownLatch = new CountDownLatch(1);
    // 连接对象
    ZooKeeper zooKeeper;

    // 用户生成序号的节点
    String defaultPath = "/uniqueId";

    @Override
    public void process(WatchedEvent event) {
        try {
            // 捕获事件状态
            if (event.getType() == Event.EventType.None) {
                if (event.getState() == Event.KeeperState.SyncConnected) {
                    System.out.println("连接成功");
                    countDownLatch.countDown();
                } else if (event.getState() == Event.KeeperState.Disconnected) {
                    System.out.println("连接断开!");
                } else if (event.getState() == Event.KeeperState.Expired) {
                    System.out.println("连接超时!");
                    // 超时后服务器端已经将连接释放，需要重新连接服务器端
                    zooKeeper = new ZooKeeper("127.0.0.1:2181", 6000, new GloballyUniqueId());
                } else if (event.getState() == Event.KeeperState.AuthFailed) {
                    System.out.println("验证失败!");
                }
            }
        } catch (Exception ex) {
            ex.printStackTrace();
        }

    }

    // 构造方法
    public GloballyUniqueId() {
        try {
            //打开连接
            zooKeeper = new ZooKeeper(IP, 5000, this);
            // 阻塞线程，等待连接的创建成功
            countDownLatch.await();

        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }

    // 生成id的方法
    public String getUniqueId() {
        String path = "";
        try {
            // 创建临时有序节点
            path = zooKeeper.create(defaultPath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);
        } catch (Exception ex) {
            ex.printStackTrace();
        }
        System.err.println("path: "+path);
        // /uniqueId0000000001 截取id号
        return path.substring(9);
    }

    public static void main(String[] args) {
        GloballyUniqueId globallyUniqueId = new GloballyUniqueId();
        for (int i = 1; i <= 5; i++) {
            String id = globallyUniqueId.getUniqueId();
            System.out.println(Long.parseLong(id));
        }
    }

}

```

#### 分布式锁

```java
public class DistributeLock {
    // ZK的连接地址
    String IP = "127.0.0.1:2181";
    // 计数器对象
    CountDownLatch countDownLatch = new CountDownLatch(1);

    // zookeeper配置信息
    ZooKeeper zooKeeper;

    private static final String LOCK_ROOT_PATH = "/Locks/Unique";
    private static final String LOCK_NODE_NAME = "Tickets_";
    // 完整的临时有序节点路径
    private String lockPath;


    //监视器
    Watcher watcher = new Watcher() {
        @Override
        public void process(WatchedEvent watchedEvent) {
            if(watchedEvent.getType()==Event.EventType.NodeDeleted){
                synchronized (this){
                    notifyAll();
                }
            }

        }
    };

    public DistributeLock() {
        try {
            zooKeeper = new ZooKeeper(IP, 5000, new Watcher() {
                @Override
                public void process(WatchedEvent event) {
                    if (event.getType() == Event.EventType.None) {
                        if (event.getState() == Event.KeeperState.SyncConnected) {
                            System.out.println("连接成功");
                            countDownLatch.countDown();
                        }
                    }
                }
            });
            countDownLatch.await();
        } catch (Exception ex) {
            ex.printStackTrace();
        }
    }


    public  void acquireLock() throws  Exception{
        // 创建锁节点
        createLock();
        // 尝试获取锁
        attemptLock();
    }

    private void createLock() throws Exception {
        // 其实随时在动态创建节点
        //判断Locks父节点是否存在，不存在就创建
        Stat stat = zooKeeper.exists(LOCK_ROOT_PATH, false);
        if (stat == null) {
            zooKeeper.create(LOCK_ROOT_PATH, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }
        // 创建了临时有序节点 /Locks/Unique/Tickets__0000000000   /Locks/Unique/Tickets__0000000001
        lockPath = zooKeeper.create(LOCK_ROOT_PATH + "/" + LOCK_NODE_NAME, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);
        System.err.println("节点创建成功" + lockPath);
    }

    // 定义最小的节点是锁的持有者
    private void attemptLock() throws Exception {
        // 1. 获取Locks节点下的所有节点
        List<String> list = zooKeeper.getChildren(LOCK_ROOT_PATH, false);
        //对子节点进行排序
        Collections.sort(list);

        // 2. 拿到当前的节点的位置的索引
        String curName = lockPath.substring(LOCK_ROOT_PATH.length() + 1);
        int index = list.indexOf(curName);
        if (index == 0) {
            System.err.println("节点获取锁成功："+curName);
            return;
        } else {
            // 3. 否则拿到上一个节点的路径, 盯着上一个节点
            String path = list.get(index - 1);
            Stat stat = zooKeeper.exists(LOCK_ROOT_PATH + "/" + path, watcher);
            if (null == stat) {
                // 4. 怕的是上一个节点在上述的查找过程中被删除了，所以尝试再次尝试获取锁
                attemptLock();
            } else {
                // 5. 如果没删除，那么就监视上一个节点
                synchronized (watcher) {
                    watcher.wait();
                }
                attemptLock();
            }
        }
    }

    //释放锁,完整路径，注意注意  节点的之在这里很不重要
    public void releaseLock() throws Exception {
        // 删除临时有序节点
        zooKeeper.delete(this.lockPath, -1);
        zooKeeper.close();
        System.err.println("锁已经释放:" + this.lockPath);
    }
```

## 一、安装zookeeper集群最终免搜索版

### 1.1 配置文件

zoo1.cfg

```sh
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/usr/local/zookeeper_3510/data_1
# the port at which the clients will connect
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1
server.1=localhost:2287:3387
server.2=localhost:2288:3388
server.3=localhost:2289:3389

```

zoo2.cfg

```sh
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/usr/local/zookeeper_3510/data_2
# the port at which the clients will connect
clientPort=2182
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1
server.1=localhost:2287:3387
server.2=localhost:2288:3388
server.3=localhost:2289:3389


```

zoo3.cfg

```sh
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/usr/local/zookeeper_3510/data_3
# the port at which the clients will connect
clientPort=2183
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1
server.1=localhost:2287:3387
server.2=localhost:2288:3388
server.3=localhost:2289:3389



```

记得创建以上data目录，并在该目录下创建myid文件，内容分别是1,2,3

### 1.2 启动脚本

启动脚本

```sh
#!/bin/bash
export ZOOKEEPER_HOME=/usr/local/zookeeper_3510
${ZOOKEEPER_HOME}/bin/zkServer.sh start /usr/local/zookeeper_3510/conf/zoo1.cfg
${ZOOKEEPER_HOME}/bin/zkServer.sh start /usr/local/zookeeper_3510/conf/zoo2.cfg
${ZOOKEEPER_HOME}/bin/zkServer.sh start /usr/local/zookeeper_3510/conf/zoo3.cfg
```

### 1.3 dockerfile

Dockerfile

```dockerfile
FROM centos:centos7
MAINTAINER 13265317096@163.com


# 把java添加到容器中  ADD命令会自动处理URL和解压tar压缩包
ADD jdk1.8.0_333.tar.gz /usr/local/
# 已经包含了zookeeper的一系列设置zookeeper_3510.tar.gz
ADD zookeeper_3510.tar.gz /usr/local/
ADD zookeeper_start.sh  /usr/local/

RUN yum -y install vim

RUN chmod 755 /usr/local/zookeeper_start.sh


#配置java与环境变量
ENV  JAVA_HOME /usr/local/jdk1.8.0_333
ENV  JRE_HOME  $JAVA_HOME/jre 
ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
ENV PATH $PATH:$JAVA_HOME/bin:$JRE_HOME/bin

ENTRYPOINT /usr/local/zookeeper_start.sh
```

### 1.4 构建镜像

```shell
docker build --platform linux/amd64 -t dexlace/zookeeper .
```

```sh
docker network create zk-net
```

```shell
docker run -d --name  zk1 \
--restart always  \
-e JVMFLAGS="-Xmx1024m" \
-v /Users/dexlace/docker/zk-run-dir/zk1/zoo1.cfg:/usr/local/zookeeper_3510/conf/zoo.cfg \
-v /Users/dexlace/docker/zk-run-dir/zk1/data/myid:/usr/local/zookeeper_3510/data/myid \
--network zk-net --network-alias zk1 \
-p 2181:2181   dexlace/zookeeper:latest
```

```shell
docker run -d --name  zk2 \
--restart always  \
-e JVMFLAGS="-Xmx1024m" \
-v /Users/dexlace/docker/zk-run-dir/zk2/zoo2.cfg:/usr/local/zookeeper_3510/conf/zoo.cfg \
-v /Users/dexlace/docker/zk-run-dir/zk2/data/myid:/usr/local/zookeeper_3510/data/myid \
--network zk-net --network-alias zk2 \
-p 2182:2181   dexlace/zookeeper:latest
```

```shell
docker run  --name  zk3 \
--restart always  \
-e JVMFLAGS="-Xmx1024m" \
-v /Users/dexlace/docker/zk-run-dir/zk3/zoo3.cfg:/usr/local/zookeeper_3510/conf/zoo.cfg \
-v /Users/dexlace/docker/zk-run-dir/zk3/data/myid:/usr/local/zookeeper_3510/data/myid \
--network zk-net --network-alias zk3 \
-p 2183:2181   dexlace/zookeeper:latest
```







